# Rate Limiting Integration Guide (v0.2.8)

## Version History
- v0.2.8: Initial integration guide
  - Component integration
  - Configuration management
  - Middleware setup
  - Monitoring integration

## Overview
Complete integration guide for the rate limiting system, combining all components into a cohesive solution.

## Implementation

### Application Setup
```typescript
import { Hono } from 'hono';
import { RateLimitDO } from './rate-limit/do';
import { SessionManager } from './rate-limit/session';
import { TokenBucketManager } from './rate-limit/token';
import { ErrorTracker } from './rate-limit/error';
import { RateLimitMonitor } from './rate-limit/monitor';
import { createLogger } from './rate-limit/logging';

export function createApp(env: Env): Hono {
  const app = new Hono();
  
  // Initialize components
  const logger = createLogger(env);
  const monitor = new RateLimitMonitor(logger, env);
  const errorTracker = new ErrorTracker(logger, monitor);
  
  const sessionConfig = {
    maxAge: 24 * 60 * 60 * 1000, // 24 hours
    cleanupInterval: 60 * 60 * 1000, // 1 hour
    tokenRefillRate: 1, // 1 token per second
    maxTokens: 100
  };

  const sessionManager = new SessionManager(
    sessionConfig,
    logger,
    env.RATE_LIMIT.storage
  );

  const tokenBucketManager = new TokenBucketManager(
    sessionConfig,
    env.RATE_LIMIT.storage
  );

  // Setup middleware
  app.use('*', async (c, next) => {
    try {
      return await next();
    } catch (err) {
      errorTracker.track(err);
      throw err;
    }
  });

  const rateLimiter = new RateLimitSessionMiddleware(
    sessionManager,
    tokenBucketManager,
    logger
  );

  app.use('*', rateLimiter.middleware());

  // Health check
  app.get('/health', (c) => {
    return c.json({ status: 'ok' });
  });

  return app;
}
```

### Configuration Management
```typescript
interface RateLimitConfig {
  session: SessionConfig;
  monitoring: {
    metrics: string[];
    alerts: AlertConfig[];
  };
  deployment: {
    environments: Record<string, EnvConfig>;
    rollout: RolloutConfig;
  };
}

export const loadConfig = async (
  env: Env
): Promise<RateLimitConfig> => {
  // Load from KV or environment
  const config = await env.KV.get('rate-limit-config');
  
  if (!config) {
    return getDefaultConfig(env);
  }

  return JSON.parse(config);
};

export const updateConfig = async (
  env: Env,
  config: Partial<RateLimitConfig>
): Promise<void> => {
  const current = await loadConfig(env);
  const updated = {
    ...current,
    ...config
  };

  await validateConfig(updated);
  await env.KV.put('rate-limit-config', JSON.stringify(updated));
};
```

### Monitoring Integration
```typescript
export const setupMonitoring = async (
  env: Env,
  config: RateLimitConfig
): Promise<void> => {
  // Setup metrics
  const metrics = [
    'rate_limit.requests.total',
    'rate_limit.requests.blocked',
    'rate_limit.sessions.active',
    'rate_limit.errors.total',
    'rate_limit.latency.p95'
  ];

  await Promise.all(
    metrics.map(metric => 
      env.MONITORING.createMetric(metric)
    )
  );

  // Setup alerts
  const alerts = [
    {
      name: 'High Error Rate',
      query: 'rate(rate_limit.errors.total[5m]) > 10',
      severity: 'critical'
    },
    {
      name: 'High Block Rate',
      query: 'rate_limit.requests.blocked / rate_limit.requests.total > 0.2',
      severity: 'warning'
    }
  ];

  await Promise.all(
    alerts.map(alert =>
      env.MONITORING.createAlert(alert)
    )
  );
}
```

### Deployment Integration
```typescript
export const setupDeployment = async (
  env: Env,
  config: RateLimitConfig
): Promise<void> => {
  // Validate environment
  const envConfig = config.deployment.environments[env.ENVIRONMENT];
  if (!envConfig) {
    throw new Error(`Invalid environment: ${env.ENVIRONMENT}`);
  }

  // Setup rollout
  const rollout = new GradualRollout({
    percentage: config.deployment.rollout.percentage,
    duration: config.deployment.rollout.duration,
    metrics: {
      errorThreshold: 0.01,
      latencyThreshold: 200
    }
  });

  // Monitor deployment
  rollout.on('step', async (percentage) => {
    await env.MONITORING.putMetric(
      'rate_limit.rollout.percentage',
      percentage
    );
  });

  rollout.on('error', async (error) => {
    await autoRollback({
      errorRate: error.metrics.errorRate,
      latencyP95: error.metrics.latencyP95
    });
  });

  // Start rollout
  await rollout.start();
}
```

## Component Integration

### Middleware Chain
```typescript
const middleware = [
  // 1. Error handling
  errorHandler(logger),
  
  // 2. Session validation
  sessionMiddleware(sessionManager),
  
  // 3. Rate limiting
  rateLimitMiddleware(rateLimiter),
  
  // 4. Circuit breaker
  circuitBreakerMiddleware(circuitBreaker),
  
  // 5. Logging
  loggingMiddleware(logger)
];

app.use('*', ...middleware);
```

### Error Handling
```typescript
app.onError((err, c) => {
  if (err instanceof RateLimitError) {
    errorTracker.track(err);
    
    return c.json(
      formatResponse(c.get('rateLimitContext'), err)
    );
  }
  
  return c.json({
    error: {
      code: 'INTERNAL_ERROR',
      message: 'An unexpected error occurred'
    }
  }, 500);
});
```

## Testing Integration

### Test Setup
```typescript
describe('Rate Limiting Integration', () => {
  let app: Hono;
  let env: Env;

  beforeEach(async () => {
    env = createTestEnv();
    app = createApp(env);
  });

  it('should integrate all components', async () => {
    const res = await app.fetch(
      new Request('http://localhost/test')
    );
    
    expect(res.status).toBe(200);
    expect(res.headers.get('X-RateLimit-Limit')).toBe('100');
  });
});
```

## Monitoring Integration

### Metrics Collection
```typescript
const metrics = {
  requests: new Counter('rate_limit_requests_total'),
  blocked: new Counter('rate_limit_requests_blocked'),
  errors: new Counter('rate_limit_errors_total'),
  sessions: new Gauge('rate_limit_sessions_active'),
  latency: new Histogram('rate_limit_request_duration_ms')
};

export const collectMetrics = () => {
  return async (c: Context, next: Next) => {
    const start = Date.now();
    
    try {
      await next();
    } finally {
      metrics.latency.observe(Date.now() - start);
      metrics.requests.inc();
      
      if (c.res.status === 429) {
        metrics.blocked.inc();
      }
    }
  };
};
```

## Notes
- Test integration points
- Monitor component health
- Track performance metrics
- Document failure modes
- Update runbooks 